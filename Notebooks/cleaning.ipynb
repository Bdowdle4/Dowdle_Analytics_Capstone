{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0645e5cc",
   "metadata": {},
   "source": [
    "# Predicting Procurement Compliance Using KPI-Driven Machine Learning Models\n",
    "\n",
    "**Author:** Brittany Dowdle\n",
    "\n",
    "**Date:** 7/4/2025\n",
    "\n",
    "**Objective:** This notebook is part of the overall [capstone project](https://github.com/Bdowdle4/Dowdle_Analytics_Capstone). The ultimate goal is to identify patterns and predictors of non-compliant suppliers using machine learning techniques.\n",
    "\n",
    "## Introduction\n",
    "This project uses the [Procurement KPI Analysis Dataset](https://www.kaggle.com/datasets/shahriarkabir/procurement-kpi-analysis-dataset) to predict compliance of suppliers. The dataset includes purchase order records from 5 different suppliers from 2022-2023. To ensure data quality and model readiness, this notebook will clean and preprocess the dataset to prepare for exporatory analysis and predictive modeling. \n",
    "\n",
    "****\n",
    "\n",
    "### Imports\n",
    "In the code cell below are the necessary Python libraries for this notebook. *All imports should be at the top of the notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d652ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ad8cfd",
   "metadata": {},
   "source": [
    "****\n",
    "\n",
    "### 1. Load and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cfef12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 777 entries, 0 to 776\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   PO_ID             777 non-null    object \n",
      " 1   Supplier          777 non-null    object \n",
      " 2   Order_Date        777 non-null    object \n",
      " 3   Delivery_Date     690 non-null    object \n",
      " 4   Item_Category     777 non-null    object \n",
      " 5   Order_Status      777 non-null    object \n",
      " 6   Quantity          777 non-null    int64  \n",
      " 7   Unit_Price        777 non-null    float64\n",
      " 8   Negotiated_Price  777 non-null    float64\n",
      " 9   Defective_Units   641 non-null    float64\n",
      " 10  Compliance        777 non-null    object \n",
      "dtypes: float64(3), int64(1), object(7)\n",
      "memory usage: 66.9+ KB\n",
      "None \n",
      "\n",
      "Dataset Description:\n",
      "          Quantity  Unit_Price  Negotiated_Price  Defective_Units\n",
      "count   777.000000  777.000000        777.000000       641.000000\n",
      "mean   1094.660232   58.283822         53.660721        74.803432\n",
      "std     647.844551   28.101315         26.094930        69.187870\n",
      "min      51.000000   10.840000          9.270000         0.000000\n",
      "25%     615.000000   33.290000         30.460000        26.000000\n",
      "50%    1075.000000   58.950000         53.800000        49.000000\n",
      "75%    1548.000000   83.130000         76.550000       100.000000\n",
      "max    5000.000000  109.170000        107.390000       321.000000 \n",
      "\n",
      "First Few Rows:\n",
      "      PO_ID         Supplier  Order_Date Delivery_Date    Item_Category  \\\n",
      "0  PO-00001        Alpha_Inc  2023-10-17    2023-10-25  Office Supplies   \n",
      "1  PO-00002  Delta_Logistics  2022-04-25    2022-05-05  Office Supplies   \n",
      "2  PO-00003         Gamma_Co  2022-01-26    2022-02-15              MRO   \n",
      "3  PO-00004    Beta_Supplies  2022-10-09    2022-10-28        Packaging   \n",
      "4  PO-00005  Delta_Logistics  2022-09-08    2022-09-20    Raw Materials   \n",
      "\n",
      "  Order_Status  Quantity  Unit_Price  Negotiated_Price  Defective_Units  \\\n",
      "0    Cancelled      1176       20.13             17.81              NaN   \n",
      "1    Delivered      1509       39.32             37.34            235.0   \n",
      "2    Delivered       910       95.51             92.26             41.0   \n",
      "3    Delivered      1344       99.85             95.52            112.0   \n",
      "4    Delivered      1180       64.07             60.53            171.0   \n",
      "\n",
      "  Compliance  \n",
      "0        Yes  \n",
      "1        Yes  \n",
      "2        Yes  \n",
      "3        Yes  \n",
      "4         No   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"C:/Users/Britt/Documents/44688/Procurement KPI Analysis Dataset.csv\")\n",
    "\n",
    "# Preview the structure and details\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info(), '\\n')\n",
    "\n",
    "print(\"Dataset Description:\")\n",
    "print(df.describe(), '\\n')\n",
    "\n",
    "print(\"First Few Rows:\")\n",
    "print(df.head(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b9765c",
   "metadata": {},
   "source": [
    "### 2. Standardize Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d067df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['po_id', 'supplier', 'order_date', 'delivery_date', 'item_category',\n",
      "       'order_status', 'quantity', 'unit_price', 'negotiated_price',\n",
      "       'defective_units', 'compliance'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Convert all column names to lowercase and remove white space\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# View column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4a8c43",
   "metadata": {},
   "source": [
    "### 3. Convert Dates to Datetime Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a041b396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 777 entries, 0 to 776\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   po_id             777 non-null    object        \n",
      " 1   supplier          777 non-null    object        \n",
      " 2   order_date        777 non-null    datetime64[ns]\n",
      " 3   delivery_date     690 non-null    datetime64[ns]\n",
      " 4   item_category     777 non-null    object        \n",
      " 5   order_status      777 non-null    object        \n",
      " 6   quantity          777 non-null    int64         \n",
      " 7   unit_price        777 non-null    float64       \n",
      " 8   negotiated_price  777 non-null    float64       \n",
      " 9   defective_units   641 non-null    float64       \n",
      " 10  compliance        777 non-null    object        \n",
      "dtypes: datetime64[ns](2), float64(3), int64(1), object(5)\n",
      "memory usage: 66.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Parse date fields\n",
    "df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce')\n",
    "df['delivery_date'] = pd.to_datetime(df['delivery_date'], errors='coerce')\n",
    "\n",
    "# Verify Dtype changed\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5b8c3c",
   "metadata": {},
   "source": [
    "### 4. Handle Missing Values\n",
    "Some purchase orders marked as “Delivered” are missing their delivery_date. Instead of dropping these rows, which would result in a loss of 87 records, this project will use a data-preserving approach. It will combine supplier-specific median lead time imputation with a transparency flag to maintain data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bec6dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 777 entries, 0 to 776\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   po_id             777 non-null    object        \n",
      " 1   supplier          777 non-null    object        \n",
      " 2   order_date        777 non-null    datetime64[ns]\n",
      " 3   delivery_date     690 non-null    datetime64[ns]\n",
      " 4   item_category     777 non-null    object        \n",
      " 5   order_status      777 non-null    object        \n",
      " 6   quantity          777 non-null    int64         \n",
      " 7   unit_price        777 non-null    float64       \n",
      " 8   negotiated_price  777 non-null    float64       \n",
      " 9   defective_units   777 non-null    float64       \n",
      " 10  compliance        777 non-null    object        \n",
      "dtypes: datetime64[ns](2), float64(3), int64(1), object(5)\n",
      "memory usage: 66.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Fill missing defective_units with 0 (assuming no defects were found if null)\n",
    "df['defective_units'] = df['defective_units'].fillna(0)\n",
    "\n",
    "# Verify null count changed\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3fa7341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      po_id         supplier order_date delivery_date    item_category  \\\n",
      "0  PO-00001        Alpha_Inc 2023-10-17    2023-10-25  Office Supplies   \n",
      "1  PO-00002  Delta_Logistics 2022-04-25    2022-05-05  Office Supplies   \n",
      "2  PO-00003         Gamma_Co 2022-01-26    2022-02-15              MRO   \n",
      "3  PO-00004    Beta_Supplies 2022-10-09    2022-10-28        Packaging   \n",
      "4  PO-00005  Delta_Logistics 2022-09-08    2022-09-20    Raw Materials   \n",
      "\n",
      "  order_status  quantity  unit_price  negotiated_price  defective_units  \\\n",
      "0    Cancelled      1176       20.13             17.81              0.0   \n",
      "1    Delivered      1509       39.32             37.34            235.0   \n",
      "2    Delivered       910       95.51             92.26             41.0   \n",
      "3    Delivered      1344       99.85             95.52            112.0   \n",
      "4    Delivered      1180       64.07             60.53            171.0   \n",
      "\n",
      "  compliance  lead_time_days  delivery_date_missing_flag  \n",
      "0        Yes             8.0                           0  \n",
      "1        Yes            10.0                           0  \n",
      "2        Yes            20.0                           0  \n",
      "3        Yes            19.0                           0  \n",
      "4         No            12.0                           0  \n"
     ]
    }
   ],
   "source": [
    "# Calculate lead_time_days for rows with valid delivery_date\n",
    "df['lead_time_days'] = (df['delivery_date'] - df['order_date']).dt.days\n",
    "\n",
    "# Compute median lead time by supplier (only using valid delivery_date)\n",
    "median_lead_times = df.dropna(subset=['lead_time_days']).groupby('supplier')['lead_time_days'].median()\n",
    "\n",
    "# Create a column to flag missing delivery_date with status 'Delivered'\n",
    "df['delivery_date_missing_flag'] = df['delivery_date'].isnull() & (df['order_status'].str.lower() == 'delivered')\n",
    "\n",
    "# Convert flag column to integer\n",
    "df['delivery_date_missing_flag'] = df['delivery_date_missing_flag'].astype(int)\n",
    "# Results: 1 for True, 0 for False\n",
    "\n",
    "# Impute delivery_date using order_date + median lead time per supplier\n",
    "def impute_delivery_date(row):\n",
    "    if row['delivery_date_missing_flag']:\n",
    "        supplier = row['supplier']\n",
    "        median_days = median_lead_times.get(supplier, df['lead_time_days'].median())\n",
    "        return row['order_date'] + pd.Timedelta(days=median_days)\n",
    "    return row['delivery_date']\n",
    "\n",
    "df['delivery_date'] = df.apply(impute_delivery_date, axis=1)\n",
    "\n",
    "# Recalculate lead_time_days after imputation\n",
    "df['lead_time_days'] = (df['delivery_date'] - df['order_date']).dt.days\n",
    "\n",
    "# Show the first few rows to verify changes\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b7deb8",
   "metadata": {},
   "source": [
    "### 5. Create Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38376804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      po_id         supplier order_date delivery_date    item_category  \\\n",
      "0  PO-00001        Alpha_Inc 2023-10-17    2023-10-25  Office Supplies   \n",
      "1  PO-00002  Delta_Logistics 2022-04-25    2022-05-05  Office Supplies   \n",
      "2  PO-00003         Gamma_Co 2022-01-26    2022-02-15              MRO   \n",
      "3  PO-00004    Beta_Supplies 2022-10-09    2022-10-28        Packaging   \n",
      "4  PO-00005  Delta_Logistics 2022-09-08    2022-09-20    Raw Materials   \n",
      "\n",
      "  order_status  quantity  unit_price  negotiated_price  defective_units  \\\n",
      "0    Cancelled      1176       20.13             17.81              0.0   \n",
      "1    Delivered      1509       39.32             37.34            235.0   \n",
      "2    Delivered       910       95.51             92.26             41.0   \n",
      "3    Delivered      1344       99.85             95.52            112.0   \n",
      "4    Delivered      1180       64.07             60.53            171.0   \n",
      "\n",
      "  compliance  lead_time_days  delivery_date_missing_flag  price_diff  \\\n",
      "0        Yes             8.0                           0        2.32   \n",
      "1        Yes            10.0                           0        1.98   \n",
      "2        Yes            20.0                           0        3.25   \n",
      "3        Yes            19.0                           0        4.33   \n",
      "4         No            12.0                           0        3.54   \n",
      "\n",
      "   defect_rate  \n",
      "0     0.000000  \n",
      "1     0.155732  \n",
      "2     0.045055  \n",
      "3     0.083333  \n",
      "4     0.144915  \n"
     ]
    }
   ],
   "source": [
    "# Price difference\n",
    "df['price_diff'] = df['unit_price'] - df['negotiated_price']\n",
    "\n",
    "# Defect rate\n",
    "df['defect_rate'] = df['defective_units'] / df['quantity']\n",
    "df['defect_rate'] = df['defect_rate'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# Show first few rows to verify new columns\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658da069",
   "metadata": {},
   "source": [
    "### 6. Identify Outliers\n",
    "If less than 10% of rows contain outliers, assume it is a natural variance and leave as is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bb25b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantity: 6 outliers\n",
      "unit_price: 0 outliers\n",
      "price_diff: 8 outliers\n",
      "defect_rate: 1 outliers\n",
      "quantity: 6 outliers\n",
      "unit_price: 0 outliers\n",
      "price_diff: 8 outliers\n",
      "defect_rate: 1 outliers\n",
      "Total rows with at least one outlier: 15 \n",
      "\n",
      "Outliers: 15 of 777 rows (1.93%)\n"
     ]
    }
   ],
   "source": [
    "# Use the IQR method to determine which values are outliers\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outlier_mask = (data[column] < lower_bound) | (data[column] > upper_bound)\n",
    "    \n",
    "    print(f\"{column}: {outlier_mask.sum()} outliers\")\n",
    "    return outlier_mask\n",
    "\n",
    "# Choose columns to search in\n",
    "outlier_columns = ['quantity', 'unit_price', 'price_diff', 'defect_rate']\n",
    "\n",
    "for col in outlier_columns:\n",
    "    detect_outliers_iqr(df, col)\n",
    "\n",
    "# Provide count of rows with outliers for each column\n",
    "df['quantity_outlier'] = detect_outliers_iqr(df, 'quantity')\n",
    "df['unit_price_outlier'] = detect_outliers_iqr(df, 'unit_price')\n",
    "df['price_diff_outlier'] = detect_outliers_iqr(df, 'price_diff')\n",
    "df['defect_rate_outlier'] = detect_outliers_iqr(df, 'defect_rate')\n",
    "\n",
    "# Total number of rows with any outliers\n",
    "df['any_outlier'] = df[['quantity_outlier', 'unit_price_outlier',\n",
    "                        'price_diff_outlier', 'defect_rate_outlier']].any(axis=1)\n",
    "print(f\"Total rows with at least one outlier: {df['any_outlier'].sum()}\", '\\n')\n",
    "\n",
    "# Show percentage of rows with outliers\n",
    "outliers = 15\n",
    "total_rows = 777\n",
    "\n",
    "percentage = (outliers / total_rows) * 100\n",
    "print(f\"Outliers: {outliers} of {total_rows} rows ({percentage:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e606617",
   "metadata": {},
   "source": [
    "****\n",
    "All initial cleaning tasks are completed. Going to verify missing values were all filled before exporting the cleaned data set.\n",
    "\n",
    "### 7. Second Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6314a2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "po_id                          0\n",
       "supplier                       0\n",
       "order_date                     0\n",
       "delivery_date                 19\n",
       "item_category                  0\n",
       "order_status                   0\n",
       "quantity                       0\n",
       "unit_price                     0\n",
       "negotiated_price               0\n",
       "defective_units                0\n",
       "compliance                     0\n",
       "lead_time_days                19\n",
       "delivery_date_missing_flag     0\n",
       "price_diff                     0\n",
       "defect_rate                    0\n",
       "quantity_outlier               0\n",
       "unit_price_outlier             0\n",
       "price_diff_outlier             0\n",
       "defect_rate_outlier            0\n",
       "any_outlier                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for remaining nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "557ef858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_status\n",
       "Cancelled              8\n",
       "Pending                6\n",
       "Partially Delivered    5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the order status for remaining null values\n",
    "df[df['delivery_date'].isnull()]['order_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c22a4",
   "metadata": {},
   "source": [
    "### 8. Drop Remaining Rows Containing Null Values\n",
    "To maintain data integrity and ensure that only relevant, interpretable records are used in lead time calculations and compliance modeling, this project is dropping the 19 rows where: 8 are cancelled orders, 6 the order has not shipped yet, and 5 fulfillment is incomplete. Including these records could introduce bias or noise into the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad2c086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "po_id                         0\n",
       "supplier                      0\n",
       "order_date                    0\n",
       "delivery_date                 0\n",
       "item_category                 0\n",
       "order_status                  0\n",
       "quantity                      0\n",
       "unit_price                    0\n",
       "negotiated_price              0\n",
       "defective_units               0\n",
       "compliance                    0\n",
       "lead_time_days                0\n",
       "delivery_date_missing_flag    0\n",
       "price_diff                    0\n",
       "defect_rate                   0\n",
       "quantity_outlier              0\n",
       "unit_price_outlier            0\n",
       "price_diff_outlier            0\n",
       "defect_rate_outlier           0\n",
       "any_outlier                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define list of statuses where missing delivery_date is not \"delivered\"\n",
    "drop_statuses = ['cancelled', 'pending', 'partially delivered']\n",
    "\n",
    "# Drop rows with missing delivery_date AND status in drop_statuses\n",
    "df = df[~((df['delivery_date'].isnull()) & (df['order_status'].str.lower().isin(drop_statuses)))]\n",
    "\n",
    "# Final check for null values\n",
    "df.isnull().sum()  # Should all be 0 now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599336f3",
   "metadata": {},
   "source": [
    "****\n",
    "### Conclusion\n",
    "Export cleaned data set as a CSV to be used in exporatory data analysis next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3a0234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset\n",
    "df.to_csv(r\"C:\\Users\\Britt\\Documents\\44688\\Dowdle_Analytics_Capstone\\Data\\cleaned_procurement_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
